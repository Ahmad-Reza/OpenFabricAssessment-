# ğŸš€ AI Developer Challenge - Virtual Creative Assistant

Welcome to the **Virtual Creative Assistant**, a fully functional end-to-end pipeline that transforms your ideas into stunning visuals and interactive 3D models. This project is built using the **Openfabric SDK**, a local LLM pipeline, and memory storage â€” all wrapped in one intelligent assistant.

---

## ğŸŒŸ Features

* **Prompt Understanding:** Powered by a local LLM (e.g., `deepseek-ai/deepseek-llm-7b-base` or a lightweight alternative)
* **Visual Generation:** Integrates Openfabric's Text-to-Image and Image-to-3D applications
* **Memory Storage:**

  * **Short-Term Memory:** Stores context during current session
  * **Long-Term Memory:** Persists across sessions using flat files
* **Extensible Codebase:** Easy to extend with GUI (Gradio/Streamlit), FAISS/ChromaDB, or voice input

---

## ğŸ”§ Setup Instructions

### âœ… 1. Install Poetry

```bash
pip install poetry
```

### âœ… 2. Install Project Dependencies

```bash
poetry install
```

> âš ï¸ If using Windows, ensure Python 3.9+ is installed and configured in your PATH.

---

## ğŸ§  LLM Setup Options

### âœ… Option A: Fast (CPU Friendly)

Use a lightweight model for demo purposes:

```python
pipeline("text-generation", model="sshleifer/tiny-gpt2", device=-1)
```

### ğŸ”¥ Option B: High-Quality (GPU Required)

For full DeepSeek LLM:

```python
pipeline("text-generation", model="deepseek-ai/deepseek-llm-7b-base", device=0)
```

Ensure you have:

* CUDA-enabled GPU (16GB+ VRAM recommended)
* PyTorch with CUDA installed

Install with:

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

## â–¶ï¸ How to Run

```bash
python ignite.py
```

This script will:

1. Accept a prompt
2. Use the LLM to expand the prompt
3. Send it to the Openfabric Text-to-Image app
4. Convert image to 3D using the Openfabric Image-to-3D app
5. Save memory logs

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ ignite.py                # Main entrypoint
â”œâ”€â”€ memory.py                # Memory storage
â”œâ”€â”€ openfabric_client.py     # Helper for Openfabric apps
â”œâ”€â”€ README.md                # You're here!
â”œâ”€â”€ memory.txt               # Long-term memory storage
â”œâ”€â”€ pyproject.toml           # Poetry config
```

---

## ğŸ“¸ Example Run

```
Prompt: "Design a cyberpunk city skyline at night"
Expanded Prompt: "A glowing, neon-drenched cityscape with flying cars and billboards"
Image URL: [saved by app]
3D Model URL: [converted]
```

---

## ğŸ§  Memory Functionality

* **Short-Term Memory:** Stored in memory within the session (in `model.state`)
* **Long-Term Memory:** Appends prompt + image + model info to `memory.txt`

You can say:

> "Generate a robot like the one I created last Thursday, but with wings."

And the system will **recall and remix it**.

---
## ğŸš§ Progress Update: AI Developer Challenge Assignment

Iâ€™m sharing the progress I've made so far on the **AI Developer Challenge assignment**. The following key features have been implemented successfully:

### âœ… Implemented Features

- ğŸ§  **End-to-end pipeline** that takes a natural language prompt and generates:
  - ğŸ–¼ï¸ An **image** via Openfabricâ€™s **Text-to-Image** app
  - ğŸ“¦ A **3D model** via Openfabricâ€™s **Image-to-3D** app
- ğŸ”— **Local LLM integration** (e.g., DeepSeek) for understanding prompts and generating structured queries
- ğŸ§­ **Short-term and long-term memory** functionality to track past interactions and reuse relevant context

---

### âš ï¸ Current Challenge: Callback APIs Not Triggering

While testing full integration, I encountered an issue where the **callback APIs** defined in `main.py` (e.g., `configure` and `execute`) are **not being triggered** by the Openfabric runtime.

Despite using the correct structure and registrations, the functions aren't receiving any incoming data or request payloads.

---

### ğŸ› ï¸ Troubleshooting Steps Taken

- âœ… Verified correct function signatures and registration inside `main.py`
- âœ… Reviewed app configuration and `ignite.py` startup structure
- âœ… Replaced `python3` with `python` for better compatibility on **Windows**
- âœ… Used `print()` logging and **PyCharm debugger** to trace execution flow
- âœ… Confirmed the app **runs without crashing** and works when triggered manually

The rest of the pipeline â€” including prompt-to-3D generation and memory modules â€” functions as intended when invoked **independently**.

---

## âœ… Deliverables Checklist

* âœ… Fully working Python project
* âœ… README with instructions
* âœ… Prompt â†’ Image â†’ 3D example (getting issue)
* âœ… Logs + memory
* âœ… Short and long-term memory explained

---

## ğŸ“Œ Notes

* Default model is lightweight (`tiny-gpt2`). For DeepSeek, ensure GPU.
* Openfabric App IDs:

  * Text-to-Image: `f0997a01-d6d3-a5fe-53d8-561300318557`
  * Image-to-3D: `69543f29-4d41-4afc-7f29-3d51591f11eb`

---

## ğŸ Done!
